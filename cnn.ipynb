{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnyKong/svm-cnn-idc-detection/blob/master/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNC-D_KfXz8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9pxlVwdaPcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BASE_DIR = '/content/breast-histopathology'\n",
        "IMG_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VsWm0VBH_Qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! [ ! -d $BASE_DIR ] && git clone https://nick_lrc@bitbucket.org/nick_lrc/breast-histopathology.git\n",
        "% cd $BASE_DIR\n",
        "! rm -rf [0-9]*.pt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMAJHrxyHDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "negatives = []\n",
        "positives = []\n",
        "\n",
        "for file in glob.glob('data/0/*'):\n",
        "  image = Image.open(file)\n",
        "  if image.size == (IMG_DIM, IMG_DIM):\n",
        "    negatives.append(file)\n",
        "\n",
        "for file in glob.glob('data/1/*'):\n",
        "  image = Image.open(file)\n",
        "  if image.size == (IMG_DIM, IMG_DIM):\n",
        "    positives.append(file)\n",
        "\n",
        "print(f'Negative: {len(negatives)}')\n",
        "print(f'Positive: {len(positives)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4VexiVBvDET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 8\n",
        "BATCH_SIZE = 128\n",
        "LOG_INTERVAL = 200\n",
        "LR = 0.1\n",
        "# MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0\n",
        "# LR_STEP_SIZE = 5\n",
        "# GAMMA = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RRVN9xlfikB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_validate_test_split(data, train_ratio=0.8):\n",
        "  np.random.shuffle(data)\n",
        "  train, test = np.split(data, [int(train_ratio * len(data))])\n",
        "  train, validate = np.split(train, [int(train_ratio * len(train))])\n",
        "  return train, validate, test\n",
        "\n",
        "def negative_positive_merge(negatives, positives, negative_label=0, positive_label=1):\n",
        "  images = np.concatenate([negatives, positives])\n",
        "  labels = np.array([negative_label] * len(negatives) + [positive_label] * len(positives))\n",
        "  indices = np.random.permutation(len(images))\n",
        "  return images[indices], labels[indices]\n",
        "\n",
        "negative_train, negative_validate, negative_test = train_validate_test_split(negatives)\n",
        "positive_train, positive_validate, positive_test = train_validate_test_split(positives)\n",
        "image_train, label_train = negative_positive_merge(negative_train, positive_train)\n",
        "image_validate, label_validate = negative_positive_merge(negative_validate, positive_validate)\n",
        "image_test, label_test = negative_positive_merge(negative_test, positive_test)\n",
        "\n",
        "print(f'Train   : {len(image_train)}')\n",
        "print(f'Validate: {len(image_validate)}')\n",
        "print(f'Test    : {len(image_test)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9tc1tcga0U2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import multiprocessing\n",
        "\n",
        "class BreastHistopathologyDataset(Dataset):\n",
        "\n",
        "  def __init__(self, images, labels):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = np.array(Image.open(self.images[index])) / 255.\n",
        "    image = np.moveaxis(image, -1, -3).astype(np.float32)\n",
        "    label = self.labels[index]\n",
        "    return (image, label)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': multiprocessing.cpu_count(), 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "train_loader = DataLoader(BreastHistopathologyDataset(image_train, label_train), \n",
        "                          batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "validate_loader = DataLoader(BreastHistopathologyDataset(image_validate, label_validate), \n",
        "                             batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "test_loader = DataLoader(BreastHistopathologyDataset(image_test, label_test), \n",
        "                         batch_size=BATCH_SIZE, shuffle=True, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2ip86nsxx_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "from skimage.feature import hog\n",
        "\n",
        "def layer_output_dimension(in_dimension, kernel_size, stride=1, padding=0):\n",
        "  return (in_dimension - kernel_size + 2 * padding) // stride + 1\n",
        "\n",
        "class BreastHistopathologyClassifier(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(BreastHistopathologyClassifier, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Dropout(0.25),\n",
        "    )\n",
        "\n",
        "    self.conv_out_dim = layer_output_dimension(IMG_DIM, 3)\n",
        "    self.conv_out_dim = layer_output_dimension(self.conv_out_dim, 3)\n",
        "    self.conv_out_dim = layer_output_dimension(self.conv_out_dim, 2, 2)\n",
        "    self.conv_out_dim *= self.conv_out_dim * 64\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.conv_out_dim, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(128, 2),\n",
        "    )\n",
        "    self.accuracy = 0\n",
        "  \n",
        "  def forward(self, images):\n",
        "    out = self.conv(images)\n",
        "    out = out.view(-1, self.conv_out_dim)\n",
        "    return self.fc(out)\n",
        "\n",
        "  def loss(self, pred, label, reduction='mean'):\n",
        "    return F.cross_entropy(pred, label.squeeze().long(), reduction=reduction)\n",
        "        \n",
        "  def save_best_model(self, accuracy, dest):\n",
        "    if self.accuracy < accuracy:\n",
        "      self.accuracy = accuracy\n",
        "      torch.save(self.state_dict(), dest)\n",
        "      print(f'Saved best model to {dest}')\n",
        "\n",
        "class BreastHistopathologyClassifierWithHog(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(BreastHistopathologyClassifierWithHog, self).__init__()\n",
        "    self.conv = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(32, 64, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2, 2),\n",
        "        nn.Dropout(0.25),\n",
        "    )\n",
        "\n",
        "    self.hog_ppc = 5\n",
        "    self.hog_cpb = 10\n",
        "\n",
        "    self.conv_out_dim = layer_output_dimension(IMG_DIM, 3)\n",
        "    self.conv_out_dim = layer_output_dimension(self.conv_out_dim, 3)\n",
        "    self.conv_out_dim = layer_output_dimension(self.conv_out_dim, 2, 2)\n",
        "    self.conv_out_dim *= self.conv_out_dim * 64\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.conv_out_dim + self.hog_ppc*self.hog_ppc*8, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.5),\n",
        "        nn.Linear(128, 2),\n",
        "    )\n",
        "    self.accuracy = 0\n",
        "\n",
        "  def loss(self, pred, label, reduction='mean'):\n",
        "    return F.cross_entropy(pred, label.squeeze().long(), reduction=reduction)\n",
        "        \n",
        "  def save_best_model(self, accuracy, dest):\n",
        "    if self.accuracy < accuracy:\n",
        "      self.accuracy = accuracy\n",
        "      torch.save(self.state_dict(), dest)\n",
        "      print(f'Saved best model to {dest}')\n",
        "\n",
        "  def forward(self, images):\n",
        "    out = self.conv(images)\n",
        "    out = out.view(-1, self.conv_out_dim)\n",
        "    \n",
        "    h = lambda i : hog(i, orientations=8, pixels_per_cell=(10,10), cells_per_block=(5, 5),block_norm= 'L2')\n",
        "    im_cpu = images.cpu()\n",
        "    im_cpu = [numpy.]\n",
        "    h_out = [h(im) for im in im_cpu]\n",
        "    h_out = torch.Tensor(h_out).to(device)\n",
        "\n",
        "    out = torch.cat((h_out, out), dim=1)\n",
        "\n",
        "    return self.fc(out)\n",
        "\n",
        "model = BreastHistopathologyClassifier().to(device)\n",
        "model.load_state_dict(torch.load('LR0_1_016.pt'))\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=LR_STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psiuVV0U-lAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import traceback\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval):\n",
        "  model.train()\n",
        "  loss_sum = 0\n",
        "\n",
        "  for i, (image, label) in enumerate(train_loader):\n",
        "    image = image.to(device)\n",
        "    label = label.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(image)\n",
        "    loss = model.loss(pred, label)\n",
        "    loss_sum += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % log_interval == 0 or i == len(train_loader) - 1:\n",
        "      print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            time.ctime(time.time()),\n",
        "            epoch, \n",
        "            i * len(image), \n",
        "            len(train_loader.dataset),\n",
        "            100.0 * i / len(train_loader), \n",
        "            loss.item()))\n",
        "  return loss_sum / len(train_loader.dataset)\n",
        "\n",
        "def evaluate(model, device, eval_loader, eval_type):\n",
        "  model.eval()\n",
        "  loss_sum = 0\n",
        "  num_correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (image, label) in enumerate(eval_loader):\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      pred = model(image)\n",
        "      loss = model.loss(pred, label, reduction='sum')\n",
        "      loss_sum += loss.item()\n",
        "      pred = pred.max(1)[1]\n",
        "      correct_mask = pred.eq(label.view_as(pred))\n",
        "      num_correct += correct_mask.sum().item()\n",
        "\n",
        "  loss = loss_sum / len(eval_loader.dataset)\n",
        "  accuracy = 100.0 * num_correct / len(eval_loader.dataset)\n",
        "  print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        eval_type, loss, num_correct, len(eval_loader.dataset), accuracy))\n",
        "  return loss, accuracy\n",
        "\n",
        "def eval_to_confusion_matrix(model, device, eval_loader):\n",
        "  model.eval()\n",
        "  loss_sum = 0\n",
        "  result = [[0, 0], [0, 0]]\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (image, label) in enumerate(eval_loader):\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      pred = model(image)\n",
        "      loss = model.loss(pred, label, reduction='sum')\n",
        "      loss_sum += loss.item()\n",
        "      pred = pred.max(1)[1]\n",
        "      cm = confusion_matrix(label.view_as(pred).cpu(), pred.cpu())\n",
        "      result[0][0] += cm[0][0]\n",
        "      result[0][1] += cm[0][1]\n",
        "      result[1][0] += cm[1][0]\n",
        "      result[1][1] += cm[1][1]\n",
        "\n",
        "  loss = loss_sum / len(eval_loader.dataset)\n",
        "  return loss, result\n",
        "\n",
        "def plot(epochs, history, title, history_label, figsize=(20, 10)):\n",
        "  plt.figure(figsize=figsize)\n",
        "  plt.plot(epochs, history)\n",
        "  plt.title(title)\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(history_label)\n",
        "  plt.savefig(f'{title.lower().replace(\" \", \"_\")}.png')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41YyHx2HuTTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_history = []\n",
        "validate_loss_history = []\n",
        "validate_accuracy_history = []\n",
        "validate_accuracy = 0\n",
        "\n",
        "try:\n",
        "  for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss = train(model, device, train_loader, optimizer, epoch, LOG_INTERVAL)\n",
        "    validate_loss, validate_accuracy = evaluate(model, device, validate_loader, \"Validate\")\n",
        "    train_loss_history.append((epoch, train_loss))\n",
        "    validate_loss_history.append((epoch, validate_loss))\n",
        "    validate_accuracy_history.append((epoch, validate_accuracy))\n",
        "    model.save_best_model(validate_accuracy, f'{epoch:03}.pt')\n",
        "\n",
        "  evaluate(model, device, test_loader, \"Test\")\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "  print('Interrupted')\n",
        "except:\n",
        "  traceback.print_exc()\n",
        "finally:\n",
        "  model.save_best_model(validate_accuracy, f'{epoch:03}.pt')\n",
        "  epochs, losses = zip(*train_loss_history)\n",
        "  plot(epochs, losses, 'Train Loss', 'loss')\n",
        "  epochs, losses = zip(*validate_loss_history)\n",
        "  plot(epochs, losses, 'Validation Loss', 'loss')\n",
        "  epochs, accuracies = zip(*validate_accuracy_history)\n",
        "  plot(epochs, accuracies, 'Validation Accuracy', 'accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OzicC2hvcQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(cm):\n",
        "  tn = cm[0][0]\n",
        "  fp = cm[0][1]\n",
        "  fn = cm[1][0]\n",
        "  tp = cm[1][1]\n",
        "  return (tn+tp)/(tn+fp+fn+tp)\n",
        "def recall(cm):\n",
        "  tn = cm[0][0]\n",
        "  fp = cm[0][1]\n",
        "  fn = cm[1][0]\n",
        "  tp = cm[1][1]\n",
        "  return tp/(tp+fn)\n",
        "def precision(cm):\n",
        "  tn = cm[0][0]\n",
        "  fp = cm[0][1]\n",
        "  fn = cm[1][0]\n",
        "  tp = cm[1][1]\n",
        "  return tp/(tp+fp)\n",
        "def all_info(tn, fp, fn, tp):\n",
        "  cm = [[tn, fp], [fn, tp]]\n",
        "  print('a', accuracy(cm))\n",
        "  print('r', recall(cm))\n",
        "  print('p', precision(cm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYKo1t3MuNND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BreastHistopathologyClassifierWithHog().to(device)\n",
        "model.load_state_dict(torch.load('LR0_1_Hog_010.pt'))\n",
        "\n",
        "loss, cm = eval_to_confusion_matrix(model, device, test_loader)\n",
        "print(loss)\n",
        "print(cm)\n",
        "print(accuracy(cm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EUCg2PgoegS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# demo\n",
        "\n",
        "import random\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "def try_img(model, img_path, ground_truth):\n",
        "  model.eval()\n",
        "\n",
        "  img_display = Image.open(img_path)\n",
        "\n",
        "  im = np.array(img_display) / 255.\n",
        "  im = np.moveaxis(im, -1, -3).astype(np.float32)\n",
        "  image = torch.Tensor([im]).to(device)\n",
        "  label = torch.Tensor([ground_truth]).to(device)\n",
        "  pred = model(image)\n",
        "  pred = pred.max(1)[1]\n",
        "  return img_display, pred.sum().item(), ground_truth\n",
        "\n",
        "def show_grid(imgs, preds, truths):\n",
        "  fig = plt.figure(figsize=(12., 12.))\n",
        "  grid = ImageGrid(fig, 111,\n",
        "      nrows_ncols=(4, 5),\n",
        "      axes_pad=.8,\n",
        "      )\n",
        "\n",
        "  for ax, im, p, t in zip(grid, imgs, preds, truths):\n",
        "    ax.imshow(im)\n",
        "    ax.set_title('ground truth: {}\\nprediction: {}'.format(t, p))\n",
        "  plt.savefig('demo.png')\n",
        "\n",
        "model = BreastHistopathologyClassifier().to(device)\n",
        "model.load_state_dict(torch.load('LR0_1_016.pt'))\n",
        "\n",
        "imgs = []\n",
        "preds = []\n",
        "truths = []\n",
        "for i in range(10):\n",
        "  rand = random.randrange(len(positive_test))\n",
        "  im, p, t = try_img(model, positive_test[rand], 1)\n",
        "  imgs.append(im)\n",
        "  preds.append(p)\n",
        "  truths.append(t)\n",
        "\n",
        "for i in range(10):\n",
        "  rand = random.randrange(len(negative_test))\n",
        "  im, p, t = try_img(model, negative_test[rand], 0)\n",
        "  imgs.append(im)\n",
        "  preds.append(p)\n",
        "  truths.append(t)\n",
        "\n",
        "show_grid(imgs, preds, truths)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYcySRjXvggB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate stats\n",
        "# cnn\n",
        "all_info(34891,4400,3139,12615)\n",
        "all_info(36297,2994,2426,11508)\n",
        "all_info(36647,2644,6126,9628)\n",
        "all_info(36144,3147,3393,12361)\n",
        "\n",
        "# svm\n",
        "print('svm')\n",
        "all_info(64284,33943,6114,32270)\n",
        "all_info(49800,48427,4606,34778)\n",
        "all_info(54092,44134,4919,34465)\n",
        "all_info(56823,41404,5733,33651)\n",
        "all_info(0,98227,0,39384)\n",
        "all_info(49539,48688,4503,34881)\n",
        "all_info(48188,50039,4248,35136)\n",
        "all_info(3046,95181,274,39110)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}