{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM with Data",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnyKong/svm-cnn-idc-detection/blob/master/SVM_with_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udo4BK16RdeM",
        "colab_type": "text"
      },
      "source": [
        "setup kaggle (Now deceperated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co0aRCa0OTpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2IXbVxPRivz",
        "colab_type": "text"
      },
      "source": [
        "download & unzip dataset (Now deceperated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1gkLtf8QVbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images -p /content\n",
        "!unzip -q -d /content/dataset /content/breast-histopathology-images.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwBx6KisagVn",
        "colab_type": "text"
      },
      "source": [
        "New way to download dataset (git bucket)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdiF_VLaUa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup dataset param(s)\n",
        "BASE_DIR = '/content/breast-histopathology'\n",
        "IMG_DIM = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_4y-DduaHt2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup dataset\n",
        "! [ ! -d $BASE_DIR ] && git clone https://nick_lrc@bitbucket.org/nick_lrc/breast-histopathology.git\n",
        "% cd $BASE_DIR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFuqd3XJh_dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup training param(s)\n",
        "BATCH_SIZE = 128\n",
        "LOG_INTERVAL = 20\n",
        "\n",
        "# hog settings\n",
        "PIXEL_PER_CELL = 5\n",
        "CELL_PER_BLOCK = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMAJHrxyHDjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset statistics (#negative: 196454, #positive: 78768)\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "negatives = []\n",
        "positives = []\n",
        "\n",
        "# count negative samples\n",
        "for file in glob.glob('data/0/*'):\n",
        "  image = Image.open(file)\n",
        "  if image.size == (IMG_DIM, IMG_DIM):\n",
        "    negatives.append(file)\n",
        "\n",
        "# count positive samples\n",
        "for file in glob.glob('data/1/*'):\n",
        "  image = Image.open(file)\n",
        "  if image.size == (IMG_DIM, IMG_DIM):\n",
        "    positives.append(file)\n",
        "\n",
        "print(f'Negative: {len(negatives)}')\n",
        "print(f'Positive: {len(positives)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vR71WbDS3aH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper methods\n",
        "import glob\n",
        "import fnmatch\n",
        "import cv2\n",
        "from functools import reduce\n",
        "\n",
        "# Find all images\n",
        "def find_images(*argv):\n",
        "  imgs = []\n",
        "  for p in argv:\n",
        "    if p[-1] is not '/':\n",
        "      p += '/'\n",
        "    imgs += glob.glob(p + '**/*.png', recursive=True)\n",
        "  return imgs\n",
        "\n",
        "# Split data set into training set and test set by ratio 8 : 2\n",
        "def train_test_split(data, train_ratio=0.8):\n",
        "  np.random.shuffle(data)\n",
        "  return np.split(data, [int(train_ratio * len(data))])\n",
        "\n",
        "# Merge negative and positive images randomly\n",
        "def negative_positive_merge(negatives, positives, negative_label=0, positive_label=1):\n",
        "  images = np.concatenate([negatives, positives])\n",
        "  labels = np.array([negative_label] * len(negatives) + [positive_label] * len(positives))\n",
        "  indices = np.random.permutation(len(images))\n",
        "  return images[indices], labels[indices]\n",
        "\n",
        "# Load an image\n",
        "def load_img(path):\n",
        "  im = cv2.imread(path)\n",
        "  return im\n",
        "\n",
        "# Load images from start to end\n",
        "def load_imgs(imgs, start, end):\n",
        "  values=[]\n",
        "  labels=[]\n",
        "  for i in range(start, end):\n",
        "    im = imgs[i]\n",
        "    values.append(load_img(im))\n",
        "    if fnmatch.fnmatch(im, '*class0.png'):\n",
        "      labels.append(0)\n",
        "    elif fnmatch.fnmatch(im, '*class1.png'):\n",
        "      labels.append(1)\n",
        "    else:\n",
        "      raise Exception('image with no class: ' + im)\n",
        "  return (values, labels)\n",
        "\n",
        "# load images\n",
        "def load_equal_pn_imgs(imgs, total_num):\n",
        "  neg = fnmatch.filter(imgs, '*class0.png')\n",
        "  pos = fnmatch.filter(imgs, '*class1.png')\n",
        "\n",
        "  total_num = min(total_num, min(len(neg),len(pos)) * 2)\n",
        "  values = []\n",
        "  labels = []\n",
        "  print('loading {} images'.format(total_num))\n",
        "  for i in range(total_num >> 1):\n",
        "    values.append(load_img(neg[i]))\n",
        "    labels.append(0)\n",
        "    values.append(load_img(pos[i]))\n",
        "    labels.append(1)\n",
        "  return (values, labels)\n",
        "\n",
        "# Print results\n",
        "def print_data_desc(labels):\n",
        "  print('total number of images: {}'.format(len(labels)))\n",
        "  print('number of negative images: {}'.format(reduce(lambda a,b: a+1 if b == 0 else a, labels)))\n",
        "  print('number of positive images: {}'.format(reduce(lambda a,b: a+1 if b == 1 else a, labels)))\n",
        "\n",
        "# Test accuracy\n",
        "def test_output(expects, output):\n",
        "  tp = 0\n",
        "  fp = 0\n",
        "  tn = 0\n",
        "  fn = 0\n",
        "\n",
        "  for i in range(len(output)):\n",
        "    e = expects[i]\n",
        "    o = output[i]\n",
        "    if e == 0:\n",
        "      if o == 0:\n",
        "        tn += 1\n",
        "      elif o == 1:\n",
        "        fp += 1\n",
        "      else:\n",
        "        print(o)\n",
        "        raise Exception(\"unexpected class: {}\".format(o))\n",
        "    elif e == 1:\n",
        "      if o == 0:\n",
        "        fn += 1\n",
        "      elif o == 1:\n",
        "        tp += 1\n",
        "      else:\n",
        "        print(o)\n",
        "        raise Exception(\"unexpected class: {}\".format(o))\n",
        "    else:\n",
        "      raise Exception(\"unexpected class: {}\".format(o))\n",
        "    \n",
        "  print(\"TP: \", tp)\n",
        "  print(\"FP: \", fp)\n",
        "  print(\"TN: \", tn)\n",
        "  print(\"FN: \", fn)\n",
        "  print(\"Accuarcy: \", (tp + tn) / (tp + fp + tn + fn))\n",
        "  return tp, fp, tn, fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9N640R1jSyZh",
        "colab_type": "text"
      },
      "source": [
        "Now start training here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J95HAEXodsO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "from sklearn import svm\n",
        "from skimage import color\n",
        "from skimage.feature import hog\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Hog\n",
        "def hog_features(img):\n",
        "  img = color.rgb2gray(img)\n",
        "  return hog(img, orientations=8, pixels_per_cell=(PIXEL_PER_CELL,PIXEL_PER_CELL), cells_per_block=(CELL_PER_BLOCK, CELL_PER_BLOCK),block_norm= 'L2')\n",
        "\n",
        "# Hog with rgb\n",
        "def hog_features_rgb(img):\n",
        "  h = lambda i : hog(i, orientations=8, pixels_per_cell=(PIXEL_PER_CELL,PIXEL_PER_CELL), cells_per_block=(CELL_PER_BLOCK, CELL_PER_BLOCK),block_norm= 'L2')\n",
        "  return np.concatenate([h(img[:,:,0]), h(img[:,:,1]), h(img[:,:,2])])\n",
        "\n",
        "# Flatten images\n",
        "def flatten_data(img):\n",
        "  return np.array(img).reshape(IMG_DIM*IMG_DIM*3)\n",
        "\n",
        "#  Evaluate test results\n",
        "def eval_svm(clf, tests, expects):\n",
        "  outputs = clf.predict(tests)\n",
        "  num_correct = 0\n",
        "  result = []\n",
        "  for i in range(len(outputs)):\n",
        "    result.append(outputs[i] == expects[i])\n",
        "  return result\n",
        "\n",
        "# Train SVM\n",
        "# train_imgs and test_imgs are given as np arrays\n",
        "#   iter is for ADABoost (commented out)\n",
        "def train_svm(clf, data_train, feature_fn, iter=1):\n",
        "  batch_num = 0\n",
        "  for k in range(iter):\n",
        "    eval_results = []\n",
        "    for i in range(0, len(data_train), BATCH_SIZE):\n",
        "      end = min(len(data_train), i+BATCH_SIZE)\n",
        "      (values, labels) = load_imgs(data_train, i, end)\n",
        "      values = [feature_fn(im) for im in values]\n",
        "      # clf.fit(values, labels, weights[i:end])\n",
        "      clf.fit(values, labels)\n",
        "\n",
        "    #   eval_results += eval_svm(clf, values, labels)\n",
        "      if batch_num % 20 == 0 or end == len(data_train):\n",
        "        print('{} Train Iter: {} [{}/{} ({:.0f}%)]'.format(\n",
        "            time.ctime(time.time()),\n",
        "            k, \n",
        "            i,\n",
        "            len(data_train),\n",
        "            100.0 * i / len(data_train)))\n",
        "      batch_num += 1\n",
        "    \n",
        "    # num_correct = 0\n",
        "    # for r in eval_results:\n",
        "    #   if r:\n",
        "    #     num_correct += 1\n",
        "    # w_sum = 0\n",
        "    # misclassified_percent = (len(weights)-num_correct)/len(weights)\n",
        "    # for i in range(len(weights)):\n",
        "    #   if eval_results[i]:\n",
        "    #     weights[i] -= misclassified_percent\n",
        "    #   w_sum += weights[i]\n",
        "    # for i in range(len(weights)):\n",
        "    #   weights[i] /= w_sum\n",
        "  \n",
        "  return clf\n",
        "\n",
        "#  Test SVM\n",
        "def test_svm(clf, data, feature_fn):\n",
        "  result = [[0, 0], [0, 0]]\n",
        "  for i in range(0, len(data), BATCH_SIZE):\n",
        "    end = min(len(data), i+BATCH_SIZE)\n",
        "    (tests, expects) = load_imgs(data, i, end)\n",
        "    tests = [feature_fn(i) for i in tests]\n",
        "    cm = confusion_matrix(expects, clf.predict(tests))\n",
        "    result[0][0] += cm[0][0]\n",
        "    result[0][1] += cm[0][1]\n",
        "    result[1][0] += cm[1][0]\n",
        "    result[1][1] += cm[1][1]\n",
        "  \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt7FEB6tr8TN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup training (preprocessing)\n",
        "train_n, test_n = train_test_split(negatives, train_ratio=0.5)\n",
        "train_p, test_p = train_test_split(positives, train_ratio=0.5)\n",
        "data_train, label_train = negative_positive_merge(train_n, train_p)\n",
        "data_test, label_test = negative_positive_merge(test_n, test_p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L9Q9fSmkZWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run SVM\n",
        "\n",
        "# Helper method - hyper data\n",
        "def hyper_data(*argv):\n",
        "  return lambda img : np.concatenate([f(img) for f in argv])\n",
        "\n",
        "# Compute Accuracy\n",
        "def accuracy(cm):\n",
        "  tn = cm[0][0]\n",
        "  fp = cm[0][1]\n",
        "  fn = cm[1][0]\n",
        "  tp = cm[1][1]\n",
        "  return (tn+tp)/(tn+fp+fn+tp)\n",
        "\n",
        "# Run SVM\n",
        "def run_svm():\n",
        "  ff = flatten_data     # which descriptor (if any) to use\n",
        "  clf = svm.SVC(kernel='rbf')\n",
        "\n",
        "  print_data_desc(label_train)\n",
        "  train_svm(clf, data_train, ff)\n",
        "\n",
        "  # (tests, expects) = load_imgs(data_test, 0, 2000)\n",
        "  # tests = [extract_features(i) for i in tests]\n",
        "  # print(clf.score(tests, expects))\n",
        "  # test_svm(clf, data_train, ff)\n",
        "  cm = test_svm(clf, data_test, ff)\n",
        "  print(cm)\n",
        "  print(accuracy(cm))\n",
        "\n",
        "run_svm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ9srwD8kaPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Temp (for debugging)\n",
        "\n",
        "# Size of data test\n",
        "len(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}